{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"train\"\n",
    "DATATYPE = \"train:ordered\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/msc'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download files\n",
    "from parlai.tasks.convai2.build import build as convai2_build\n",
    "from parlai.tasks.msc.build import build as msc_build\n",
    "\n",
    "convai2_build(opt={\"datapath\": \"./data\"})\n",
    "msc_build(opt={\"datapath\": \"./data\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:37:30 | loading normalized fbdialog data: ./data/ConvAI2/valid_both_revised_no_cands.txt\n",
      "16:37:30 | loading fbdialog data: ./data/ConvAI2/valid_both_revised_no_cands.txt\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from parlai.core.teachers import FbDeprecatedDialogTeacher\n",
    "from parlai.tasks.convai2.agents import _path\n",
    "from parlai.tasks.msc.agents import Session1NormalizedTrait\n",
    "\n",
    "\n",
    "class BothRevisedTeacher(FbDeprecatedDialogTeacher):\n",
    "    def __init__(self, opt, shared=None):\n",
    "        opt = copy.deepcopy(opt)\n",
    "        try:\n",
    "            cands = opt[\"task\"].split(\":\")[2]\n",
    "            use_cands = False if cands == \"no_cands\" else True\n",
    "        except Exception:\n",
    "            use_cands = True\n",
    "        opt[\"datafile\"] = _path(opt, \"both_revised\", use_cands)\n",
    "        super().__init__(opt, shared)\n",
    "\n",
    "\n",
    "class Session1BothTeacher(Session1NormalizedTrait, BothRevisedTeacher):\n",
    "    pass\n",
    "\n",
    "\n",
    "opt = {\n",
    "    \"max_num_turns\": -1,\n",
    "    \"your_persona_first\": True,\n",
    "    \"datapath\": \"./data\",\n",
    "    \"datatype\": f\"{DATATYPE}\",\n",
    "    \"task\": \"::no_cands\",\n",
    "}\n",
    "data = Session1BothTeacher(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "7801\n"
     ]
    }
   ],
   "source": [
    "print(data.num_episodes())\n",
    "print(data.num_examples())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7801/7801 [00:00<00:00, 336716.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "dataset = []\n",
    "episode = []\n",
    "it = iter(data)\n",
    "\n",
    "for i in tqdm(range(data.num_examples())):\n",
    "    sample = next(it)\n",
    "    if sample[\"text\"]:\n",
    "        if \"__silence__\" in sample[\"text\"]:\n",
    "            break\n",
    "        episode.append(sample[\"text\"])\n",
    "        try:\n",
    "            episode.append(sample[\"labels\"][0])\n",
    "        except KeyError:\n",
    "            episode.append(sample[\"eval_labels\"][0])\n",
    "\n",
    "    if sample[\"episode_done\"] and episode:\n",
    "        dataset.append(episode)\n",
    "        episode = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 15602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"your persona: I've been know to finish almost two dozen novels in a twelve month period.\\nyour persona: My part time gig has me doing some pretty brave things.\\nyour persona: I have special dietary restrictions.\\nyour persona: My mom and dad divorced when I was young.\\npartner's persona: Bride of chucky is the best film out there.\\npartner's persona: My wife works, so I take care of our children.\\npartner's persona: I dad was an employee of a big diy store.\\npartner's persona: For ten years I was employed in meeting peoples needs.\\npartner's persona: My kid finished his elementary education last year.\\nHello what are doing today?\",\n",
       " 'I am good, I just got off work and tired, I have two jobs.',\n",
       " 'I just got done watching a horror movie',\n",
       " \"I rather read, I've read about 20 books this year.\",\n",
       " 'Wow! I do love a good horror movie. Loving this cooler weather',\n",
       " 'But a good movie is always good.',\n",
       " 'Yes! My son is in junior high and I just started letting him watch them too',\n",
       " 'I work in the movies as well.',\n",
       " 'Neat!! I used to work in the human services field',\n",
       " 'Yes it is neat, I stunt double, it is so much fun and hard work.',\n",
       " 'Yes I bet you can get hurt. My wife works and I stay at home',\n",
       " 'Nice, I only have one parent so now I help out my mom.',\n",
       " 'I bet she appreciates that very much.',\n",
       " 'She raised me right, I am just like her.',\n",
       " 'My dad was always busy working at home depot',\n",
       " 'Now that I am older home depot is my toy r us.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dataset), sum(len(e) for e in dataset))\n",
    "dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 20509.94it/s]\n"
     ]
    }
   ],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "new_dataset = []\n",
    "\n",
    "for i, episode in tqdm(enumerate(dataset)):\n",
    "    sample = {}\n",
    "    sample[\"personas\"] = [\n",
    "        [\n",
    "            line.strip(\"partner's persona: \")\n",
    "            for line in episode[0].split(\"\\n\")\n",
    "            if line.startswith(\"partner's persona:\")\n",
    "        ],\n",
    "        [\n",
    "            line.strip(\"your persona: \")\n",
    "            for line in episode[0].split(\"\\n\")\n",
    "            if line.startswith(\"your persona:\")\n",
    "        ],\n",
    "    ]\n",
    "\n",
    "    text = [episode[0].split(\"\\n\")[-1]] + episode[1:]\n",
    "    sample[\"dialog\"] = [\n",
    "        {\"text\": t, \"id\": speaker, \"convai2_id\": f\"{DATATYPE}_{i}\"}\n",
    "        for t, speaker in zip(text, cycle([\"Speaker 1\", \"Speaker 2\"]))\n",
    "    ]\n",
    "\n",
    "    sample[\"metadata\"] = {\"initial_data_id\": f\"{DATATYPE}_{i}\", \"session_id\": 0}\n",
    "\n",
    "    new_dataset.append(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset as JSONL file\n",
    "import json\n",
    "\n",
    "with open(f\"./data/msc/msc/msc_dialogue/session_1/{DATA}.jsonl\", \"w\") as f:\n",
    "    for sample in new_dataset:\n",
    "        f.write(json.dumps(sample) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
